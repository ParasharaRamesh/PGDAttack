{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# About\n",
    "\n",
    "This notebook attempts to finetune a resnet model to be more Robust by leveraging Projected Gradient Descent (PGD) in the two different ways:\n",
    "1. include it as a part of the dataset\n",
    "2. include the projected gradient as well while training along with the regular gradient from the loss function "
   ],
   "id": "9befb1ddab3e4144"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Importing required libraries\n",
   "id": "876d5185378e4464"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:12:50.895228Z",
     "start_time": "2024-09-08T12:12:50.883924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install lightning[extra]\n",
    "# !pip install tensorboard"
   ],
   "id": "d359d5eb64ade957",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:21.444617Z",
     "start_time": "2024-09-08T12:17:21.437243Z"
    }
   },
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import copy"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Setup",
   "id": "5f6951e549aa8a2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:21.771818Z",
     "start_time": "2024-09-08T12:17:21.756174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manual seed for reproducibility\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Params for PGD\n",
    "ALPHA = 2/255\n",
    "STEPS = 20\n",
    "EPSILON = 8/255\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {DEVICE}\")\n",
    "\n",
    "# model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "# print(\"initialized the model\")"
   ],
   "id": "8e43067e9bcd293c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Creating a finetuning dataset\n",
    "\n",
    "Idea is to create a balanced finetuning dataset which is run only once to be saved onto the disk and then from there we can just create dataloaders on that for finetuning"
   ],
   "id": "42b55ed2273fd35d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Reusing the same PGD attacker class from before",
   "id": "baeda959f22ce163"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:22.228012Z",
     "start_time": "2024-09-08T12:17:22.196743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResnetPGDAttacker:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        The PGD attack on Resnet model.\n",
    "        :param model: The resnet model on which we perform the attack\n",
    "        :param dataloader: The dataloader loading the input data on which we perform the attack\n",
    "        '''\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.adv_images = []\n",
    "        self.labels = []\n",
    "        self.eps = 0\n",
    "        self.alpha = 0\n",
    "        self.steps = 0\n",
    "        self.acc = 0\n",
    "        self.adv_acc = 0\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        # Nullify gradient for model params\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def pgd_attack(self, image, label, eps=None, alpha=None, steps=None):\n",
    "        '''\n",
    "        Create adversarial images for given batch of images and labels\n",
    "\n",
    "        :param image: Batch of input images on which we perform the attack, size (BATCH_SIZE, 3, 224, 224)\n",
    "        :param label: Batch of input labels on which we perform the attack, size (BATCH_SIZE)\n",
    "        :return: Adversarial images for the given input images\n",
    "        '''\n",
    "        if eps is None:\n",
    "            eps = self.eps\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "        if steps is None:\n",
    "            steps = self.steps\n",
    "\n",
    "        images = image.clone().detach().to(self.device)\n",
    "        adv_images = images.clone()\n",
    "        labels = label.clone().detach().to(self.device)\n",
    "\n",
    "        # Starting at a uniformly random point within the eps ball\n",
    "        random_noise = torch.zeros_like(adv_images).uniform_(-eps, eps)\n",
    "        adv_images = adv_images + random_noise\n",
    "\n",
    "        for _ in range(steps):\n",
    "            # Enable gradient tracking for adversarial images\n",
    "            adv_images.requires_grad = True\n",
    "\n",
    "            # Get model predictions and apply softmax\n",
    "            outputs = self.model(adv_images).softmax(1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "            # Compute gradient wrt images\n",
    "            grad = torch.autograd.grad(\n",
    "                loss, adv_images, retain_graph=False, create_graph=False\n",
    "            )[0]\n",
    "            adv_images = adv_images.detach()\n",
    "\n",
    "            # Gradient update\n",
    "            adv_images = adv_images + alpha * grad.sign()  # Update adversarial images using the sign of the gradient\n",
    "\n",
    "            # Projection step\n",
    "            # Clamping the adversarial images to ensure they are within the Lâˆž ball of eps radius of original image\n",
    "            adv_images = torch.clamp(adv_images, images - eps, images + eps)\n",
    "\n",
    "            adv_images = adv_images.detach()\n",
    "\n",
    "        return adv_images  # Return the generated adversarial images\n",
    "\n"
   ],
   "id": "13d4022de5445e2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Creating a finetuned dataset and saving it in disk",
   "id": "aa8168ce97b94c82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:22.494684Z",
     "start_time": "2024-09-08T12:17:22.479053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FineTuneDatasetGenerator:\n",
    "    def __init__(self, num_classes=1000, num_images_per_class=4, num_transforms=3, num_perturbations=2,\n",
    "                 save_path=\"./dataset\"\n",
    "                 ):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_images_per_class = num_images_per_class\n",
    "        self.num_transforms = num_transforms\n",
    "        self.num_perturbations = num_perturbations\n",
    "        self.save_path = save_path\n",
    "        \n",
    "        # Create the save directory if it doesn't exist\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "        weights = ResNet50_Weights.DEFAULT\n",
    "        self.resnet_transform = weights.transforms()  #PIL -> tensor\n",
    "\n",
    "        self.transformations = [\n",
    "            transforms.Compose([\n",
    "                transforms.RandomRotation(15)\n",
    "            ]),\n",
    "            transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15)\n",
    "            ]),\n",
    "            transforms.Compose([\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(15)\n",
    "            ])\n",
    "        ]\n",
    "\n",
    "        self.pgd_attacker = ResnetPGDAttacker()\n",
    "\n",
    "        self.ds = load_dataset(\"ILSVRC/imagenet-1k\", split=\"train\", streaming=True, trust_remote_code=True)\n",
    "        self.ds = self.ds.shuffle()\n",
    "        print(f\"Fine Tune Dataset Generator has been initialized.\")\n",
    "\n",
    "    def save_datapoint_with_augmentation_and_perturbations(self, img, label):\n",
    "        images = []\n",
    "        tensor_img = self.resnet_transform(img)\n",
    "\n",
    "        #original image\n",
    "        images.append(tensor_img)\n",
    "\n",
    "        #augmentations (will be four)\n",
    "        for _ in range(self.num_transforms):\n",
    "            transformed_img = random.choice(self.transformations)(img)\n",
    "            transformed_tensor_img = self.resnet_transform(transformed_img)\n",
    "            images.append(transformed_tensor_img)\n",
    "\n",
    "        #perturbations on all images thus far\n",
    "        batch = list(\n",
    "            map(\n",
    "                lambda img: img.to(\"cpu\"),\n",
    "                images\n",
    "            )\n",
    "        )\n",
    "        # Get a batch of images and create corresponding labels\n",
    "        img_batch = torch.stack(batch)\n",
    "        label_batch = torch.tensor([label] * len(img_batch))  # Repeat the label for the batch\n",
    "\n",
    "        for _ in range(self.num_perturbations):\n",
    "            # Generate random parameters for PGD attack\n",
    "            random_eps = random.uniform(0.01, 0.3)\n",
    "            random_alpha = random.uniform(0.01, 0.1)\n",
    "            random_steps = random.randint(15, 20)\n",
    "\n",
    "            # Perform the PGD attack\n",
    "            perturbed_images = self.pgd_attacker.pgd_attack(img_batch,\n",
    "                                                            label_batch,\n",
    "                                                            eps=random_eps,\n",
    "                                                            alpha=random_alpha,\n",
    "                                                            steps=random_steps)\n",
    "\n",
    "            for perturbed_img in perturbed_images:\n",
    "                images.append(perturbed_img)\n",
    "\n",
    "        #save this\n",
    "        self.save_images(images, label)\n",
    "\n",
    "    def generate(self):\n",
    "        for label in tqdm(range(self.num_classes), desc=\"Fetching images for each class\"):\n",
    "            # Define the filter function for the current class label\n",
    "            def filter_class(example):\n",
    "                return example['label'] == label and example['image'].mode == 'RGB'\n",
    "\n",
    "            # Load the dataset and filter for the current class\n",
    "            ds = copy.deepcopy(self.ds)\n",
    "            ds = ds.filter(filter_class)\n",
    "\n",
    "            # Use take to get the desired number of images\n",
    "            ds = ds.take(self.num_images_per_class)\n",
    "\n",
    "            i = 0\n",
    "            for data in ds:\n",
    "                img = data[\"image\"]\n",
    "                self.save_datapoint_with_augmentation_and_perturbations(img, label)\n",
    "                i += 1\n",
    "                if i == self.num_images_per_class:\n",
    "                    break\n",
    "\n",
    "            print(\n",
    "                f\"Saved {self.num_images_per_class * (1 + self.num_transforms) * self.num_perturbations} images for class {label}.\"\n",
    "            )\n",
    "\n",
    "    def save_images(self, images, label):\n",
    "        for idx, image in enumerate(images):\n",
    "            img_id = str(uuid.uuid4())\n",
    "            save_file = os.path.join(self.save_path, f\"class_{label}_img_{img_id}.pt\")\n",
    "            torch.save(image, save_file)\n",
    "\n",
    "        del images\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# fine_tune_gen = FineTuneDatasetGenerator(num_perturbations=2, num_transforms=2, num_images_per_class=2, num_classes=2)\n",
    "# fine_tune_gen.generate()\n"
   ],
   "id": "13682654a99a1177",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.3 Creating a Pytorch dataset and dataloaders over the saved data in the disk",
   "id": "24e3bcde543f5989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:22.781690Z",
     "start_time": "2024-09-08T12:17:22.765678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "class FineTunedDataset(Dataset):\n",
    "    def __init__(self, root_dir, device=DEVICE):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = os.listdir(root_dir)\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image from the file\n",
    "        image_file = self.image_files[idx]\n",
    "        image = torch.load(os.path.join(self.root_dir, image_file)).to(self.device)\n",
    "\n",
    "        # Extract label from the filename\n",
    "        label = int(os.path.basename(image_file).split(\"_\")[1])\n",
    "        label = torch.tensor(label).to(self.device)  # e.g., \"class_0_img_3.pt\" -> label = 0\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_dataloaders(root_dir, batch_size, train_val_test_split):\n",
    "    dataset = FineTunedDataset(root_dir)\n",
    "\n",
    "    train_size = int(len(dataset) * train_val_test_split[0])\n",
    "    val_size = int(len(dataset) * train_val_test_split[1])\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ],
   "id": "7eeddfed982403a2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:22.956245Z",
     "start_time": "2024-09-08T12:17:22.940597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"C:\\\\Parashara\\\\Projects\\\\NUS projects\\\\Sem3\\\\Trustworthy ML\\\\Assignment 1\\\\PGDAttack\\\\dataset\"\n",
    "train_loader, val_loader, test_loader = get_dataloaders(path, batch_size=1, train_val_test_split=[0.33, 0.33, 0.33])"
   ],
   "id": "c0e6bf8c971e36e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Implementing Robust Resnet",
   "id": "f2b608c00b6103c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T13:05:16.425278Z",
     "start_time": "2024-09-08T13:03:46.530765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RobustPGDResnet(LightningModule):\n",
    "    def __init__(self, train_loader=train_loader, val_loader=val_loader, test_loader=val_loader, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.learning_rate = learning_rate\n",
    "        self.accuracy_metric = Accuracy(\"multiclass\", num_classes=1000)\n",
    "\n",
    "        # Important: This property activates manual optimization.\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_pgd_loss(self, images, labels):\n",
    "        # Randomize PGD parameters\n",
    "        eps = random.uniform(0.01, 0.3)\n",
    "        alpha = random.uniform(0.01, 0.1)\n",
    "        steps = random.randint(5, 13)\n",
    "\n",
    "        # Create adversarial images\n",
    "        adv_images = images.clone().detach().requires_grad_(True)\n",
    "\n",
    "        # Starting at a uniformly random point within the eps ball\n",
    "        random_noise = torch.zeros_like(adv_images).uniform_(-eps, eps)\n",
    "        adv_images = adv_images + random_noise\n",
    "\n",
    "        # PGD process\n",
    "        for _ in range(steps):\n",
    "            outputs = self.model(adv_images)\n",
    "\n",
    "            # Calculate PGD loss\n",
    "            pgd_loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "            #Manual calculation of grad\n",
    "            grad = torch.autograd.grad(pgd_loss, adv_images, retain_graph=True)[0]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Gradient update\n",
    "                adv_images = adv_images + alpha * grad.sign()\n",
    "                adv_images = torch.clamp(adv_images, images - eps, images + eps)\n",
    "                \n",
    "            adv_images = adv_images.detach().requires_grad_(True)\n",
    "\n",
    "        return pgd_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        # Manually optimize\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "\n",
    "        # Forward pass\n",
    "        logits = self.model(images)\n",
    "        ce_loss = self.loss_fn(logits, labels)\n",
    "\n",
    "        # Compute PGD loss\n",
    "        pgd_loss = self.compute_pgd_loss(images, labels)\n",
    "\n",
    "        # Combine losses (you can adjust the weighting)\n",
    "        total_loss = ce_loss + pgd_loss\n",
    "\n",
    "        # Backward pass\n",
    "        self.manual_backward(total_loss)\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        # compute accuracy\n",
    "        train_acc = self.accuracy_metric(logits, labels)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('train_ce_loss', ce_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_pgd_loss', pgd_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_loss', total_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', train_acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.model(images)\n",
    "        ce_loss = self.loss_fn(logits, labels)\n",
    "        val_acc = self.accuracy_metric(logits, labels)\n",
    "        self.log('val_loss', ce_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', val_acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        logits = self.model(images)\n",
    "        ce_loss = self.loss_fn(logits, labels)\n",
    "        test_acc = self.accuracy_metric(logits, labels)\n",
    "        self.log('test_loss', ce_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_acc', test_acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_loader\n",
    "\n",
    "\n",
    "#TODO.x just for testing out pgd\n",
    "# Create the classifier\n",
    "classifier = RobustPGDResnet(train_loader, val_loader, test_loader)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # Monitor validation loss for saving the best model\n",
    "    dirpath='./pgd_checkpoints/',  # Directory where checkpoints will be saved\n",
    "    filename='best-checkpoint',  # Checkpoint filename\n",
    "    save_top_k=1,  # Save only the best model\n",
    "    mode='min'  # Minimize the monitored metric\n",
    ")\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    # fast_dev_run =True, #Flag for debugging\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # profiler=\"simple\", In case you want to time each step\n",
    "    max_epochs=2,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    # val_check_interval=0.5, Use this in case the epoch takes too long, fraction of epoch\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    logger=TensorBoardLogger(save_dir='./logs', name=\"ft_pgd_resnet\")\n",
    ")\n",
    "# Other interesting flags\n",
    "#max_time=some timedelta\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(classifier)\n",
    "\n"
   ],
   "id": "a5b174707ef2807f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | model           | ResNet             | 25.6 M | train\n",
      "1 | loss_fn         | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy_metric | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.228   Total estimated model params size (MB)\n",
      "153       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9719e03c93a4ddeb00fcc392920c588"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_21324\\2244312642.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(os.path.join(self.root_dir, image_file)).to(self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b88d2ca6439a43709c5a4694236b96b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_21324\\2244312642.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(os.path.join(self.root_dir, image_file)).to(self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60b1a3aa4f0c41f6a3210238a9641c28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "762536a179b14e5985e0b194e05ce445"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.1 Training the model",
   "id": "52ef8f413b8a4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T12:17:30.936794Z",
     "start_time": "2024-09-08T12:17:24.978183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the classifier\n",
    "classifier = RobustResnet(train_loader, val_loader, test_loader)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',  # Monitor validation loss for saving the best model\n",
    "    dirpath='./pgd_checkpoints/',  # Directory where checkpoints will be saved\n",
    "    filename='best-checkpoint',  # Checkpoint filename\n",
    "    save_top_k=1,  # Save only the best model\n",
    "    mode='min'  # Minimize the monitored metric\n",
    ")\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    # fast_dev_run =True, #Flag for debugging\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # profiler=\"simple\", In case you want to time each step\n",
    "    max_epochs=4,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    check_val_every_n_epoch=1,\n",
    "    # val_check_interval=0.5, Use this in case the epoch takes too long, fraction of epoch\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    logger=TensorBoardLogger(save_dir='./logs', name=\"ft_pgd_resnet\")\n",
    ")\n",
    "    # Other interesting flags\n",
    "    #max_time=some timedelta\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(classifier)\n",
    "\n"
   ],
   "id": "5b8ccd73ff3dcac6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type               | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | model           | ResNet             | 25.6 M | train\n",
      "1 | loss_fn         | CrossEntropyLoss   | 0      | train\n",
      "2 | accuracy_metric | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------------\n",
      "25.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 M    Total params\n",
      "102.228   Total estimated model params size (MB)\n",
      "153       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b886a1b5cfc49998495b96adb580b7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\anaconda3\\envs\\trustworthyml\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_21324\\2244312642.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(os.path.join(self.root_dir, image_file)).to(self.device)\n",
      "C:\\Users\\paras\\anaconda3\\envs\\trustworthyml\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "949579a6e7474a94a94f42b3e5c535c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "162bb613640849dca7259dabfe0903e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93fbc71bdd0748f4820b1b72266a2e56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39d7522c9bb74ab19f6aebf368c09545"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21e5ddb6bca94447bcd2ee9b7905fe32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.2 Tensorboard visualizations",
   "id": "637583d02a60f625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T13:06:04.310493Z",
     "start_time": "2024-09-08T13:06:00.565598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs/ft_pgd_resnet/"
   ],
   "id": "be727aefe3b8073a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-58eb0a1ebaca6c2c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-58eb0a1ebaca6c2c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.3 Testing the trained model",
   "id": "688d96ea9ab5f043"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test the model (can pass checkpoint path also)\n",
    "trainer.test()"
   ],
   "id": "778377282eab7dde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Evaluating Results",
   "id": "f2232fa60d92bde6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1 Evaluating the best model from checkpoint",
   "id": "efce8c959ebc17ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:26:50.530760Z",
     "start_time": "2024-09-08T11:26:50.292563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model_from_checkpoint(checkpoint_path):\n",
    "    # Option 1: Use pytorch lightning\n",
    "    finetuned_model = RobustResnet.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Option 2: Regular approach\n",
    "    # Load the checkpoint\n",
    "    # checkpoint = torch.load(checkpoint_path)\n",
    "    # \n",
    "    # # Create a new instance of your model\n",
    "    # finetuned_model = RobustResnet()  # Initialize with the required parameters\n",
    "    # \n",
    "    # # Load the model weights from the checkpoint\n",
    "    # finetuned_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return finetuned_model\n",
    "\n",
    "\n",
    "def evaluate_model(test_loader=test_loader, checkpoint_path=\"./checkpoints/best-checkpoint.ckpt\",\n",
    "                   original_model=resnet50(weights=ResNet50_Weights.DEFAULT), device=DEVICE):\n",
    "    # Load the fine-tuned model from the checkpoint\n",
    "    fine_tuned_model = load_model_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Move models to the appropriate device\n",
    "    original_model.to(device)\n",
    "    fine_tuned_model.to(device)\n",
    "\n",
    "    # set to eval modes\n",
    "    original_model.eval()\n",
    "    fine_tuned_model.eval()\n",
    "\n",
    "    # Initialize accuracy metrics\n",
    "    total = 0\n",
    "    orig_correct = 0\n",
    "    ft_correct = 0\n",
    "\n",
    "    # Evaluate the original model\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images, labels = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Original model predictions\n",
    "            original_logits = original_model(images).softmax(1)\n",
    "            original_predictions = original_logits.argmax(dim=1)\n",
    "\n",
    "            # Fine-tuned model predictions\n",
    "            fine_tuned_logits = fine_tuned_model(images).softmax(1)\n",
    "            fine_tuned_predictions = fine_tuned_logits.argmax(dim=1)\n",
    "\n",
    "            # Accumulate accuracy counts\n",
    "            orig_correct += torch.sum(original_predictions == labels).item()\n",
    "            ft_correct += torch.sum(fine_tuned_predictions == labels).item()\n",
    "            total += len(labels)\n",
    "\n",
    "    # Calculate accuracies\n",
    "    original_accuracy = orig_correct / total\n",
    "    fine_tuned_accuracy = ft_correct / total\n",
    "\n",
    "    print(f'Evaluation Original Model Accuracy: {original_accuracy * 100} %')\n",
    "    print(f'Evaluation Fine-Tuned Model Accuracy: {fine_tuned_accuracy * 100} %')\n",
    "\n",
    "    return original_accuracy, fine_tuned_accuracy"
   ],
   "id": "eed147733535b4b9",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:26:51.609219Z",
     "start_time": "2024-09-08T11:26:50.562259Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_model()",
   "id": "36a97090dc29f6f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Original Model Accuracy: 100.0 %\n",
      "Evaluation Fine-Tuned Model Accuracy: 100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paras\\AppData\\Local\\Temp\\ipykernel_14884\\2244312642.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image = torch.load(os.path.join(self.root_dir, image_file)).to(self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
