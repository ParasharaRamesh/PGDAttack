{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# About\n",
    "\n",
    "This notebook does the following things at a high level:\n",
    "1. code for generating adversarial PGD images and saving it to be used for fine-tuning\n",
    "2. some visualizations of the perturbed images\n",
    "3. creating the dataset (with some random augmentations)\n",
    "4. finetuning the robust model  \n",
    "5. evaluating on test set "
   ],
   "id": "9befb1ddab3e4144"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Importing required libraries\n",
   "id": "876d5185378e4464"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import random\n",
    "import os\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Setup",
   "id": "5f6951e549aa8a2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Manual seed for reproducibility\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Params for PGD\n",
    "ALPHA = 2/255\n",
    "STEPS = 20\n",
    "EPSILON = 8/255\n"
   ],
   "id": "8e43067e9bcd293c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Loading the model",
   "id": "ecc4c4b8b915da80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "preprocess = weights.transforms()"
   ],
   "id": "2ff42231a70a45ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Loading the datasets",
   "id": "547319e9ec62f2d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_img(example):\n",
    "    example['image'] = preprocess(example['image'])\n",
    "    return example\n",
    "\n",
    "def get_dataloader(split: str, batch_num: int, batch_size: int):\n",
    "    '''\n",
    "        \n",
    "    :param split: can be either train, test or validation \n",
    "    :return: \n",
    "    '''\n",
    "    print(f\"Loading {split} ILSVRC/imagenet-1k dataset...\")\n",
    "    ds = load_dataset(\"ILSVRC/imagenet-1k\", split=split, streaming=True, trust_remote_code=True)\n",
    "    \n",
    "    # Filter out grayscale images\n",
    "    ds = ds.filter(lambda example: example['image'].mode == 'RGB')\n",
    "    \n",
    "    # Preprocess function will be applied to images on-the-fly whenever they are being accessed in the loop\n",
    "    ds = ds.map(preprocess_img)\n",
    "    ds = ds.shuffle(seed=SEED)\n",
    "    \n",
    "    # Only take desired portion of dataset\n",
    "    ds = ds.take(batch_num * batch_size)\n",
    "    print(f\"Creating dataloader with {batch_num} batches for split {split} each with size {batch_size}\")\n",
    "    return DataLoader(ds, batch_size=batch_size)\n",
    "    "
   ],
   "id": "1e9fafc8606bddd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.3 My Resnet PGD Attacker",
   "id": "2c84e145464783a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ResnetPGDAttacker:\n",
    "    def __init__(self, model, dataloader: DataLoader):\n",
    "        '''\n",
    "        The PGD attack on Resnet model.\n",
    "        :param model: The resnet model on which we perform the attack\n",
    "        :param dataloader: The dataloader loading the input data on which we perform the attack\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.batch_size = dataloader.batch_size\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.adv_images = []\n",
    "        self.labels = []\n",
    "        self.eps = 0\n",
    "        self.alpha = 0\n",
    "        self.steps = 0\n",
    "        self.acc = 0\n",
    "        self.adv_acc = 0\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        # Nullify gradient for model params\n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def pgd_attack(self, image, label, eps=None, alpha=None, steps=None):\n",
    "        '''\n",
    "        Create adversarial images for given batch of images and labels\n",
    "\n",
    "        :param image: Batch of input images on which we perform the attack, size (BATCH_SIZE, 3, 224, 224)\n",
    "        :param label: Batch of input labels on which we perform the attack, size (BATCH_SIZE)\n",
    "        :return: Adversarial images for the given input images\n",
    "        '''\n",
    "        if eps is None:\n",
    "            eps = self.eps\n",
    "        if alpha is None:\n",
    "            alpha = self.alpha\n",
    "        if steps is None:\n",
    "            steps = self.steps\n",
    "\n",
    "        images = image.clone().detach().to(self.device)\n",
    "        adv_images = images.clone()\n",
    "        labels = label.clone().detach().to(self.device)\n",
    "\n",
    "        # Starting at a uniformly random point within the eps ball\n",
    "        random_noise = torch.zeros_like(adv_images).uniform_(-eps, eps)\n",
    "        adv_images = adv_images + random_noise\n",
    "\n",
    "        for _ in range(steps):\n",
    "            # Enable gradient tracking for adversarial images\n",
    "            adv_images.requires_grad = True\n",
    "\n",
    "            # Get model predictions and apply softmax\n",
    "            outputs = self.model(adv_images).softmax(1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "            # Compute gradient wrt images\n",
    "            grad = torch.autograd.grad(\n",
    "                loss, adv_images, retain_graph=False, create_graph=False\n",
    "            )[0]\n",
    "            adv_images = adv_images.detach()\n",
    "\n",
    "            # Gradient update\n",
    "            adv_images = adv_images + alpha * grad.sign()  # Update adversarial images using the sign of the gradient\n",
    "\n",
    "            # Projection step\n",
    "            # Clamping the adversarial images to ensure they are within the Lâˆž ball of eps radius of original image\n",
    "            adv_images = torch.clamp(adv_images, images - eps, images + eps)\n",
    "\n",
    "            adv_images = adv_images.detach()\n",
    "\n",
    "        return adv_images  # Return the generated adversarial images\n",
    "\n",
    "    def pgd_batch_attack(self, eps, alpha, steps, batch_num):\n",
    "        '''\n",
    "        Launch attack for many batches and save results as class features\n",
    "        :param eps: Epsilon value in PGD attack\n",
    "        :param alpha: Alpha value in PGD attack\n",
    "        :param steps: Step value in PGD attack\n",
    "        :param batch_num: Number of batches to run the attack on\n",
    "        :return: Update attacker accuracy on original images, accuracy on adversarial images,\n",
    "        and list of adversarial images\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.steps = steps\n",
    "        adv_correct = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        adv_images_lst = []\n",
    "        for i, inputs in enumerate(tqdm(self.dataloader, total=batch_num)):\n",
    "            if i == batch_num:\n",
    "                break\n",
    "            adv_images = self.pgd_attack(**inputs)\n",
    "            with torch.no_grad():\n",
    "                adv_outputs = self.model(adv_images).softmax(1)\n",
    "                adv_predictions = adv_outputs.argmax(dim=1).cpu()\n",
    "                outputs = self.model(inputs['image'].to(self.device)).softmax(1)\n",
    "                predictions = outputs.argmax(dim=1).cpu()\n",
    "            labels = inputs['label']\n",
    "            adv_correct += torch.sum(adv_predictions == labels).item()\n",
    "            correct += torch.sum(predictions == labels).item()\n",
    "            total += len(labels)\n",
    "            adv_images_lst.append(adv_images)\n",
    "        self.adv_images = torch.cat(adv_images_lst).cpu()\n",
    "        self.acc = correct / total\n",
    "        self.adv_acc = adv_correct / total\n",
    "\n",
    "    def compute_accuracy(self, batch_num):\n",
    "        '''\n",
    "        Compute model accuracy for specified number of data batches from self.dataloader\n",
    "        :param batch_num: Number of batches on which we compute model accuracy\n",
    "        :return: Update model accuracy\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i, inputs in enumerate(tqdm(self.dataloader, total=batch_num)):\n",
    "                if i == batch_num:\n",
    "                    break\n",
    "                inputs = {k: v.to(self.device) for (k, v) in inputs.items()}\n",
    "                outputs = self.model(inputs['image']).softmax(1)\n",
    "                predictions = outputs.argmax(dim=1)\n",
    "                correct += (predictions == inputs['label']).sum().item()\n",
    "                total += predictions.size(0)\n",
    "        self.acc = correct / total"
   ],
   "id": "29fb7354c84af91b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Functions related to generating & saving + fetching saved data from a location",
   "id": "4651ce982318861a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-01T04:44:08.482744Z",
     "start_time": "2024-09-01T04:44:08.466715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fetch_perturbed_images_from_location(location: str):\n",
    "    \"\"\"\n",
    "    Fetch and concatenate all perturbed images and labels from the specified directory.\n",
    "\n",
    "    :param location: The directory where the .pt files are saved.\n",
    "    :return: Tuple of concatenated adversarial images and labels.\n",
    "    \"\"\"\n",
    "    adv_images = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate through all .pt files in the specified directory\n",
    "    for file_name in os.listdir(location):\n",
    "        if file_name.endswith(\".pt\"):\n",
    "            file_path = os.path.join(location, file_name)\n",
    "            data = torch.load(file_path)\n",
    "            adv_images.append(data['adv_images'])\n",
    "            labels.append(data['labels'])\n",
    "\n",
    "    # Concatenate all adversarial images and labels\n",
    "    adv_images = torch.cat(adv_images)\n",
    "    labels = torch.cat(labels)\n",
    "\n",
    "    return adv_images, labels\n",
    "\n",
    "def generate_adv_images(dataloader, model, store: bool = False, store_dir: str = 'adv_images'):\n",
    "    \"\"\"\n",
    "    Generate adversarial images using the PGD method and save them in a directory.\n",
    "\n",
    "    :param dataloader: dataloader of images, labels.\n",
    "    :param model: The ResNet model used for generating adversarial images.\n",
    "    :param store: Boolean flag to indicate whether to save the generated images.\n",
    "    :param store_dir: The directory where the adversarial images and labels will be saved.\n",
    "    :return: Tuple of adversarial images and their corresponding labels.\n",
    "    \"\"\"\n",
    "    # Initialize the attacker\n",
    "    attacker = ResnetPGDAttacker(model, dataloader)\n",
    "\n",
    "    # Generate adversarial images\n",
    "    adv_images = []\n",
    "    labels = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        img_batch, label_batch = batch['image'], batch['label']\n",
    "        adv_images_batch = attacker.pgd_attack(img_batch, label_batch, steps = random.randint(5, STEPS)) #randomly take 5->20 steps\n",
    "        adv_images.append(adv_images_batch)\n",
    "        labels.append(label_batch)\n",
    "\n",
    "    # Concatenate all adversarial images\n",
    "    adv_images = torch.cat(adv_images)\n",
    "    labels = torch.cat(labels)\n",
    "\n",
    "    if store:\n",
    "        # Create the store directory if it doesn't exist\n",
    "        os.makedirs(store_dir, exist_ok=True)\n",
    "    \n",
    "        # Save the adversarial images and labels in multiple files\n",
    "        for j in range(0, len(adv_images), 1000):  # Save in batches of 1000\n",
    "            start = j\n",
    "            end = min(j + 1000, len(adv_images))\n",
    "            file_path = os.path.join(store_dir, f\"adv_images_{start}-{end-1}.pt\")\n",
    "            torch.save({'adv_images': adv_images[start:end], 'labels': labels[start:end]}, file_path)\n",
    "            print(f\"Adversarial images saved at: {file_path}\")\n",
    "        \n",
    "    return store_dir, adv_images, labels"
   ],
   "id": "1e038a305a7bcbe0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Creating the fine-tuning dataset",
   "id": "daebe3fda5c80640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1e6d83ded5e4d4f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Implementing Robust Resnet",
   "id": "f2b608c00b6103c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b8ccd73ff3dcac6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Saving model & Evaluating Results",
   "id": "f2232fa60d92bde6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eed147733535b4b9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
